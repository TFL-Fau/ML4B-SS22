{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0a7d28f-c15e-4f62-959d-c893b9231f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#df2 = pd.read_csv(\"./Training_Dataframes/esken30ktweetswithemotions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "962b3619-d633-43bf-8b99-efcbd93829df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/swlh/tweet-sentiment-analysis-using-python-for-complete-beginners-4aeb4456040\n",
    "# Turning all Tweets into Vectors for later Machine learning\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "def turnTweetsIntoVector(dataframe,max_features_IN = None):\n",
    "    dataframe.drop([\"Unnamed: 0\"],axis = 1, inplace = True)\n",
    "    keyString = dataframe.keys()\n",
    "    keyString += \"Input\"\n",
    "    dataframe.columns = keyString\n",
    "    listOfTweets = dataframe[\"editedInput\"].tolist()\n",
    "    docs = np.array(listOfTweets)\n",
    "    cv=CountVectorizer(max_features = max_features_IN, binary = True)\n",
    "    oneHotCv = cv.fit_transform(docs)\n",
    "    oneHotArray = oneHotCv.toarray()\n",
    "    oneHotArray.shape\n",
    "    oneHotDf = pd.DataFrame(oneHotArray)\n",
    "    #Naming the Columns accordingly for humans to read\n",
    "    oneHotDf.columns = cv.get_feature_names_out()\n",
    "    #print(oneHotDf.head())\n",
    "    #print(oneHotDf.info())\n",
    "    longDf = pd.concat([dataframe,oneHotDf], axis = 1)\n",
    "    #dir(CountVectorizer)\n",
    "    #print(longDf.describe())\n",
    "    #longDf.head()\n",
    "    \n",
    "    # ----- To check output\n",
    "    \n",
    "    #proving, that all words in the tweet are marked appropriatly\n",
    "    #print(longDf.iloc[0][\"editedInput\"])\n",
    "    #print(longDf.iloc[0][longDf.iloc[0][\"editedInput\"].split()])\n",
    "    #Shows that keys[0:24] are tweet data, thats not part of the NLP\n",
    "    #print(longDf.keys()[:27])\n",
    "    #print(longDf.keys()[:24])\n",
    "    # -----\n",
    "\n",
    "    return longDf"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 3,
   "id": "7c2c66b7-8602-44b4-b666-a22af7e9c374",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is already part of old code\n",
    "import re\n",
    "\n",
    "def clean(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+\\s?', '', text) #Removed Mentions\n",
    "    text = re.sub(r'#', '', text) #Removed #\n",
    "    text = re.sub(r'(.)1+', r'1', text) #cleaned single letters\n",
    "    text = re.sub('((www.[^s]+)|(https?://[^s]+))','',text) #Removes links\n",
    "    text = re.sub('@','',text) #Remove @\n",
    "    text = re.sub('-','',text) #Remove -\n",
    "    text = re.sub('ä','ae',text) #Remove ä\n",
    "    text = re.sub('Ä','Ae',text) #Remove Ä\n",
    "    text = re.sub('ö','oe',text) #Remove Ä\n",
    "    text = re.sub('Ö','Oe',text) #Remove Ä\n",
    "    text = re.sub('ü','ue',text) #Remove Ä\n",
    "    text = re.sub('Ü','Ue',text) #Remove Ä\n",
    "    return text\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "st = nltk.PorterStemmer()\n",
    "def stemming_on_text(data):\n",
    "    text = [st.stem(word) for word in data]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8493cfda-0051-4df2-8cdc-c037ab39bad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_toVec(sentence,goalDF):\n",
    "    #Preparing Input text\n",
    "    cleanSentence = sentence.lower()\n",
    "    cleanSentence = clean(cleanSentence)\n",
    "    cleansentene = stemming_on_text(cleanSentence)\n",
    "    \n",
    "    #Preparing EmptyDF\n",
    "    emptyList = [0]*len(goalDF.keys())\n",
    "    #print(emptyList)\n",
    "    #print(\"Len EmptyList: \" + str(len(emptyList)))\n",
    "    #emptyDF = goalDF.iloc[0:0].copy()\n",
    "    #emptyDF = emptyDF.append(emptyList)\n",
    "    #emptyDF = emptyDF.append(pd.DataFrame(emptyList, columns = goalDF.keys()), ignore_index = True)\n",
    "    emptyDF = pd.DataFrame(columns = goalDF.keys())\n",
    "    #emptyDF.append(pd.Series(), ignore_index = True)\n",
    "    emptyDF.loc[len(emptyDF)] = emptyList\n",
    "    #print(emptyDF)\n",
    "    #emptyDF = pd.DataFrame(emptyList, columns = goalDF.keys())\n",
    "    #print(\"LenEmpty DF: \" + str(len(emptyDF)) + \" Len Keys Empty DF: \" + str(len(emptyDF.keys())))\n",
    "    \n",
    "    emptyDF[\"textInput\"][0] = sentence\n",
    "    emptyDF[\"editedInput\"][0] = cleanSentence\n",
    "    #keys = list(emptyDF.keys()[0:10])\n",
    "    #print(\"---\")\n",
    "    #print(\"New LenEmpty DF: \" + str(len(emptyDF)) + \" Len Keys Empty DF: \" + str(len(emptyDF.keys())))\n",
    "    #print(emptyDF[\"textInput\"].tolist())\n",
    "    listOfWords = cleanSentence.split()\n",
    "    for word in listOfWords:\n",
    "        if word in emptyDF.columns:\n",
    "            emptyDF[word][0] = 1\n",
    "    emptyDF.fillna(0)\n",
    "    return emptyDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf21197d-dffb-4e86-8c7c-103d2f51c079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#myPrivateSentence = \"Wir sind falsch\"    \n",
    "#print(longDf.keys()[24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9570038d-f028-4283-805b-1dd96c5c2d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "#print(list((keys)))\n",
    "def trainEmotionModels(dataFrame):\n",
    "    tweet_features = dataFrame.keys()[24:]\n",
    "    X_trainingData = dataFrame[tweet_features]\n",
    "    keys = list(dataFrame.keys()[12:20])\n",
    "    listOfModels = []\n",
    "    iterator = 0\n",
    "    for emotion in dataFrame[keys]:\n",
    "        print(emotion[:-5] + \": \")\n",
    "        #print(dataFrame[emotion].head())\n",
    "        y_emotion = dataFrame[emotion]\n",
    "        train_X, val_X, train_y, val_y = train_test_split(X_trainingData, y_emotion,test_size = 0.33, random_state = 1,shuffle=True)\n",
    "        emotion_Model = DecisionTreeRegressor(random_state = 1)\n",
    "        emotion_Model.fit(X_trainingData,y_emotion)\n",
    "        val_predictions = emotion_Model.predict(val_X)\n",
    "        listOfModels.append(emotion_Model)\n",
    "        #print(emotion_Model.predict(val_X.head()))\n",
    "        \n",
    "        print(\"Mean Absolute error for {}: \".format(emotion[:-5]) + str(round(mean_absolute_error(val_y,val_predictions)*100,2))+\"%\\n\")\n",
    "        #print(\"type(train_X): \" + str(type(train_X)))\n",
    "        #print(\"type(dfSentence): \" + str(type(dfOfSentence)))\n",
    "        #print(\"Predicition for for train_X.head() for emotion {}: \".format(emotion[:-5])+ str(emotion_Model.predict(train_X.head())))\n",
    "        #print(\"Predicition for '{}' for emotion {}: \".format(myPrivateSentence,emotion[:-5])+ str(emotion_Model.predict(dfOfSentence[tweet_features])))\n",
    "        #y_emotionGoal = dataFrame[emotion]\n",
    "        \n",
    "        \n",
    "    dicOfModels = {\"Wut-Model\":listOfModels[0],\"Vorfreude-Model\":listOfModels[1],\"Ekel-Model\":listOfModels[2],\"Furcht-Model\":listOfModels[3],\"Freude-Model\":listOfModels[4],\"Traurigkeit-Model\":listOfModels[5], \"Ueberraschungs-Model\":listOfModels[6],\"Vetrauen-Model\":listOfModels[7]}\n",
    "    return dicOfModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccc99472-e31b-43a6-b51e-3841e71ede9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAttributesOfTweet(tweetNumber, df):\n",
    "    keys = list(df.keys()[12:20])\n",
    "    print(\"---\\nTweet \\n--- \\n\" + df[\"textInput\"][tweetNumber]+\"\\n--- \\nhas these Emotions according to DataInput Tweet:\")\n",
    "    for emotion in df[keys]:\n",
    "        print(str(emotion[:-5]) + \"-Value: \" +str(df[emotion][tweetNumber]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ee4c987-f9f8-43b9-a81b-978d272a1022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpretOwnSentence(sentence, dicOfModels, df):\n",
    "    if(type(sentence) != str):\n",
    "        print(\"Sentence-Parameter is not a String\")\n",
    "        return\n",
    "    if(type(dicOfModels) != dict):\n",
    "        print(\"dicOfModels-Parameter is not a dictionary\")\n",
    "        return\n",
    "    if(len(dicOfModels)!=8):\n",
    "        print(\"dicOfModels Length is not 8\")\n",
    "        return\n",
    "        \n",
    "    #Transforming Sentence into Vector\n",
    "    dfOfSentence = sentence_toVec(sentence, df)\n",
    "    #print(\"----\\nThis is the shape of the df: \\n\" + str(dfOfSentence) + \"\\n----\")\n",
    "    listOfIndex = dfOfSentence.columns[(dfOfSentence == 1).all()].tolist()\n",
    "    listOfIndex.extend([\"textInput\",\"editedInput\",\"WutInput\"])\n",
    "    #print(\"----\\nInput Sentence was transformed to this vector: \\n\" +str(dfOfSentence.head()))\n",
    "    \n",
    "    \n",
    "    keys = list(df.keys()[12:20])\n",
    "    #Applying different Models to sentence\n",
    "    keyOfFeatures = dfOfSentence.keys()[24:]\n",
    "    features = dfOfSentence[keyOfFeatures]\n",
    "    iterator = 0\n",
    "    for model in dicOfModels:\n",
    "        #print(str(model) + \" is the following type: \" + str(type(model)))\n",
    "        result = dicOfModels[model].predict(features)\n",
    "        #print(\"---\\nThis is the result of {}: \".format(str(model)) + str(result))\n",
    "        #print(\"result[0]: \" + str(result[0]))\n",
    "        #print(\"before writing: \" + str(dfOfSentence[dfOfSentence.keys()[12+iterator]]))\n",
    "        #dfOfSentence[12+iterator] = result[0]\n",
    "        dfOfSentence[dfOfSentence.keys()[12+iterator]][0] = result[0]\n",
    "        #print(dfOfSentence[dfOfSentence.keys()[12+iterator]][0])\n",
    "        #print(\"---\\nThis is in the dfOfSentence: \" + str(dfOfSentence[12+iterator][0]))\n",
    "        if(dfOfSentence[dfOfSentence.keys()[12+iterator]][0]>1):\n",
    "            dfOfSentence[dfOfSentence.keys()[12+iterator]][0] = 1\n",
    "        iterator = iterator + 1\n",
    "    #print(\"---\\nThis is what all the Attributes look like: \\n\" + str(dfOfSentence[dfOfSentence.keys()[12:20]]))\n",
    "    getAttributesOfTweet(0,dfOfSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0ec4dd9-79df-4647-839f-0b81eb160753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "4012\n"
     ]
    }
   ],
   "source": [
    "df_esken = pd.read_csv(\"./Training_Dataframes/esken30ktweetswithemotions.csv\")\n",
    "df_scholz = pd.read_csv(\"./EmotionCSV.csv\")\n",
    "\n",
    "smallSample_esken = df_esken.iloc[:5000].copy()\n",
    "print(len(smallSample_esken))\n",
    "print(len(df_scholz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fca4e78c-6b13-4237-ac2a-232c917dc57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9012\n"
     ]
    }
   ],
   "source": [
    "mixedDF = pd.concat([df_scholz,smallSample_esken])\n",
    "mixedDF.reset_index(inplace = True)\n",
    "print(len(mixedDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "095a1c2b-e9d2-4c4b-acd2-7a2a90cc57fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizedDataframe_Mixed = turnTweetsIntoVector(mixedDF)\n",
    "#print(vectorizedDataframe_Mixed.keys()[0:26])\n",
    "vectorizedDataframe_Mixed = vectorizedDataframe_Mixed.drop(columns = [\"indexInput\"])\n",
    "#print(vectorizedDataframe_Mixed.keys()[0:26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,

   "id": "6d13c536-c0a0-4b0d-90be-1e18b725d976",
   "metadata": {},
   "outputs": [],
   "source": [
    "giveMeMyModels = trainEmotionModels(vectorizedDataframe_Mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d13c536-c0a0-4b0d-90be-1e18b725d976",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretOwnSentence(\"Wir sind wirklich ein Vorbild für alle!\", giveMeMyModels, longDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449fb545-b5b0-46c7-96e3-e298a08d19f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df_esken[\"text\"][0:5]))\n",
    "for tweet in df_esken[\"text\"][0:5]:\n",
    "    interpretOwnSentence(tweet,giveMeMyModels,longDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c83e5c1-4b46-4f0a-b7e9-f0179badb02d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
